# ë²¡í„° DB ì„œë¹„ìŠ¤ (Vector Database Service)

ì‹œê³„ì—´ ì„ë² ë”© ë° ìœ ì‚¬ë„ ê²€ìƒ‰ì„ í†µí•œ í˜ì–´ í›„ë³´ í•„í„°ë§

## ğŸ¯ ëª©ì 

í˜ì–´ íŠ¸ë ˆì´ë”©ì—ì„œ **ì¡°í•© í­ë°œ ë¬¸ì œ** í•´ê²°:

```
KOSPI200 (200ê°œ ì¢…ëª©):
- 2-way: C(200,2) = 19,900ê°œ
- 3-way: C(200,3) = 1,313,400ê°œ â† ë¶„ì„ ë¶ˆê°€ëŠ¥!

ë²¡í„° DB í•„í„°ë§ ì ìš©:
- ìœ ì‚¬í•œ ì¢…ëª©ë¼ë¦¬ë§Œ í˜ì–´ ë¶„ì„
- 19,900ê°œ â†’ 2,000ê°œ (90% ê°ì†Œ)
- ë¶„ì„ ì‹œê°„: ìˆ˜ì¼ â†’ ìˆ˜ì‹œê°„
```

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

```
íˆìŠ¤í† ë¦¬ ë°ì´í„° (OHLCV)
      â†“
ì‹œê³„ì—´ ì„ë² ë”© (25ì°¨ì› ë²¡í„°)
  â”œâ”€ í†µê³„ íŠ¹ì§• (10ì°¨ì›)
  â”œâ”€ í˜•íƒœ íŠ¹ì§• (10ì°¨ì›)
  â””â”€ ì£¼íŒŒìˆ˜ íŠ¹ì§• (5ì°¨ì›)
      â†“
Qdrant ë²¡í„° DB ì €ì¥
      â†“
ìœ ì‚¬ë„ ê²€ìƒ‰ (Cosine Similarity)
      â†“
í˜ì–´ í›„ë³´êµ° (Top 10)
```

## ğŸ”§ ì„¤ì¹˜ ë° ì‹¤í–‰

### Qdrant ì‹¤í–‰ (Docker)

```bash
# docker-composeë¡œ ì‹¤í–‰
docker-compose up -d qdrant

# ë˜ëŠ” ì§ì ‘ ì‹¤í–‰
docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant
```

### Python ì˜ì¡´ì„±

```bash
cd services/vector-db
pip install -r requirements.txt
```

### ê¸°ë³¸ ì‹¤í–‰

```bash
python main.py
```

## ğŸ“Š ì‹œê³„ì—´ ì„ë² ë”©

### 1. í†µê³„ì  íŠ¹ì§• (10ì°¨ì›)

```python
def extract_statistical_features(prices: np.ndarray) -> np.ndarray:
    """
    ìˆ˜ìµë¥  ê¸°ë°˜ í†µê³„ íŠ¹ì§• ì¶”ì¶œ
    """
    returns = np.diff(np.log(prices))

    return [
        np.mean(returns),              # 1. í‰ê·  ìˆ˜ìµë¥ 
        np.std(returns),               # 2. ë³€ë™ì„±
        skew(returns),                 # 3. ì™œë„ (ë¹„ëŒ€ì¹­ì„±)
        kurtosis(returns),             # 4. ì²¨ë„ (ê¼¬ë¦¬ ë‘ê»˜)
        sharpe_ratio,                  # 5. ìƒ¤í”„ ë¹„ìœ¨
        max_drawdown,                  # 6. ìµœëŒ€ ë‚™í­
        returns[-5:].mean(),           # 7. ìµœê·¼ 5ì¼ ëª¨ë©˜í…€
        returns[-20:].mean(),          # 8. ìµœê·¼ 20ì¼ ëª¨ë©˜í…€
        returns[-60:].mean(),          # 9. ìµœê·¼ 60ì¼ ëª¨ë©˜í…€
        volatility_ratio,              # 10. ë³€ë™ì„± ë¹„ìœ¨
    ]
```

### 2. í˜•íƒœ íŠ¹ì§• (10ì°¨ì›)

```python
def extract_shape_features(prices: np.ndarray) -> np.ndarray:
    """
    Piecewise Aggregate Approximation (PAA)
    ì‹œê³„ì—´ì„ 10ê°œ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ  ê° êµ¬ê°„ì˜ í‰ê· 
    """
    normalized = (prices - mean) / std
    segments = split_into_10_segments(normalized)
    return [segment.mean() for segment in segments]
```

**ì˜ˆì‹œ:**
```
ê°€ê²©: [100, 102, 105, 103, ...] (60ì¼)
ì •ê·œí™”: [0.0, 0.2, 0.5, 0.3, ...]
10êµ¬ê°„ í‰ê· : [0.2, 0.4, 0.3, 0.1, ...]
```

### 3. ì£¼íŒŒìˆ˜ íŠ¹ì§• (5ì°¨ì›)

```python
def extract_frequency_features(prices: np.ndarray) -> np.ndarray:
    """
    Fast Fourier Transform (FFT)
    ì£¼ê¸°ì  íŒ¨í„´ ì¶”ì¶œ
    """
    fft = np.fft.fft(prices)
    fft_abs = np.abs(fft)
    return fft_abs[1:6]  # ìƒìœ„ 5ê°œ ì£¼íŒŒìˆ˜ ì„±ë¶„
```

**í•´ì„:**
- ì €ì£¼íŒŒ: ì¥ê¸° íŠ¸ë Œë“œ
- ê³ ì£¼íŒŒ: ë‹¨ê¸° ë³€ë™

## ğŸš€ ì‚¬ìš©ë²•

### ê¸°ë³¸ ì¸ë±ì‹±

```python
from main import VectorDBService

vector_db = VectorDBService(
    host="localhost",
    port=6333,
    collection_name="stock_timeseries"
)

# ì»¬ë ‰ì…˜ ì´ˆê¸°í™”
vector_db.initialize_collection()

# ë‹¨ì¼ ì¢…ëª© ì¸ë±ì‹±
prices = np.array([...])  # 252ì¼ ì¢…ê°€ ë°ì´í„°
vector_db.index_stock('005930', prices, metadata={'name': 'ì‚¼ì„±ì „ì'})

# ë°°ì¹˜ ì¸ë±ì‹±
stock_codes = ['005930', '000660', '035420', ...]
vector_db.batch_index_stocks(stock_codes, window_days=252)
```

### ìœ ì‚¬ ì¢…ëª© ê²€ìƒ‰

```python
# ì‚¼ì„±ì „ìì™€ ìœ ì‚¬í•œ ì¢…ëª© ìƒìœ„ 10ê°œ
similar = vector_db.search_similar_stocks('005930', top_k=10)

for code, score in similar:
    print(f"{code}: {score:.4f}")

# ì¶œë ¥:
# 000660: 0.8945  (SKí•˜ì´ë‹‰ìŠ¤)
# 051910: 0.8523  (LGí™”í•™)
# 006400: 0.8312  (ì‚¼ì„±SDI)
# ...
```

### í˜ì–´ í›„ë³´ ìƒì„±

```python
# ëª¨ë“  KOSPI200 ì¢…ëª©ì˜ ìœ ì‚¬ ì¢…ëª©
candidates = {}

for stock in kospi200_stocks:
    similar = vector_db.search_similar_stocks(stock, top_k=10)
    candidates[stock] = similar

# ì´ í˜ì–´ í›„ë³´: 200 Ã— 10 = 2,000ê°œ
# (ì›ë˜ C(200,2) = 19,900ê°œì—ì„œ 90% ê°ì†Œ)
```

## ğŸ¯ ìœ ì‚¬ë„ ì¸¡ì •

### Cosine Similarity

```python
similarity = cos(Î¸) = (A Â· B) / (||A|| Ã— ||B||)

# ë²”ìœ„: -1 ~ 1
#  1.0: ì™„ì „íˆ ê°™ì€ íŒ¨í„´
#  0.0: ë¬´ê´€ê³„
# -1.0: ì •ë°˜ëŒ€ íŒ¨í„´
```

### ìœ ì‚¬ë„ í•´ì„

```
> 0.9: ê±°ì˜ ë™ì¼ (ê°™ì€ ì—…ì¢…, ETF êµ¬ì„± ì¢…ëª©)
0.8-0.9: ë§¤ìš° ìœ ì‚¬ (ê´€ë ¨ ì—…ì¢…)
0.7-0.8: ìœ ì‚¬ (í˜ì–´ íŠ¸ë ˆì´ë”© í›„ë³´)
0.6-0.7: ì•½ê°„ ìœ ì‚¬
< 0.6: ë‚®ì€ ìœ ì‚¬ë„
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### HNSW ê·¸ë˜í”„ íŒŒë¼ë¯¸í„°

```python
# Qdrant ì»¬ë ‰ì…˜ ìƒì„± ì‹œ
vectors_config = VectorParams(
    size=25,
    distance=Distance.COSINE,
    hnsw_config={
        "m": 16,              # ê·¸ë˜í”„ ì—°ê²° ìˆ˜ (ë†’ì„ìˆ˜ë¡ ì •í™•, ëŠë¦¼)
        "ef_construct": 100,  # ì¸ë±ì‹± ì •í™•ë„
    }
)
```

### ê²€ìƒ‰ íŒŒë¼ë¯¸í„°

```python
# ê²€ìƒ‰ ì‹œ
search_params = {
    "hnsw_ef": 128,  # ê²€ìƒ‰ ì •í™•ë„ (ë†’ì„ìˆ˜ë¡ ì •í™•, ëŠë¦¼)
    "exact": False,  # Trueë©´ ì™„ì „ íƒìƒ‰ (ë§¤ìš° ëŠë¦¼)
}

results = vector_db.client.search(
    collection_name="stock_timeseries",
    query_vector=vector,
    limit=10,
    search_params=search_params
)
```

### ë°°ì¹˜ ì¸ë±ì‹±

```python
# í•œ ë²ˆì— ì—¬ëŸ¬ ì¢…ëª© ì¸ë±ì‹±
points = [
    PointStruct(
        id=hash(code),
        vector=embedding.tolist(),
        payload={'stock_code': code}
    )
    for code, embedding in stock_embeddings.items()
]

vector_db.client.upsert(
    collection_name="stock_timeseries",
    points=points
)
```

## ğŸ” ê³ ê¸‰ ê¸°ëŠ¥

### ë©”íƒ€ë°ì´í„° í•„í„°ë§

```python
# íŠ¹ì • ì—…ì¢…ë§Œ ê²€ìƒ‰
results = vector_db.client.search(
    collection_name="stock_timeseries",
    query_vector=vector,
    query_filter=Filter(
        must=[
            FieldCondition(
                key="industry",
                match=MatchValue(value="ë°˜ë„ì²´")
            )
        ]
    ),
    limit=10
)
```

### ì‹œê°„ëŒ€ë³„ ì„ë² ë”©

```python
# ìµœê·¼ 60ì¼, 120ì¼, 252ì¼ ê°ê° ì„ë² ë”©
embeddings = {
    '60d': embedder.create_embedding(prices[-60:]),
    '120d': embedder.create_embedding(prices[-120:]),
    '252d': embedder.create_embedding(prices[-252:]),
}

# ë‹¨ê¸°/ì¥ê¸° ìœ ì‚¬ë„ ë¹„êµ
short_term_similar = search(embeddings['60d'])
long_term_similar = search(embeddings['252d'])
```

### ë™ì  ì„ë² ë”© ì—…ë°ì´íŠ¸

```python
# ë§¤ì¼ ì¥ ë§ˆê° í›„ ì—…ë°ì´íŠ¸
def update_embeddings_daily():
    for stock in active_stocks:
        prices = get_latest_prices(stock, days=252)
        embedding = embedder.create_embedding(prices)

        vector_db.index_stock(
            stock_code=stock,
            prices=prices,
            metadata={'updated_at': datetime.now()}
        )
```

## ğŸ¨ ì‹œê°í™”

### t-SNE ì°¨ì› ì¶•ì†Œ

```python
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

# 25ì°¨ì› â†’ 2ì°¨ì›
vectors = [...]  # ëª¨ë“  ì¢…ëª© ë²¡í„°
tsne = TSNE(n_components=2)
vectors_2d = tsne.fit_transform(vectors)

plt.scatter(vectors_2d[:, 0], vectors_2d[:, 1])
for i, code in enumerate(stock_codes):
    plt.annotate(code, (vectors_2d[i, 0], vectors_2d[i, 1]))
plt.title("Stock Embeddings (t-SNE)")
plt.show()
```

### ìœ ì‚¬ë„ íˆíŠ¸ë§µ

```python
import seaborn as sns

# ì¢…ëª© ê°„ ìœ ì‚¬ë„ í–‰ë ¬
similarity_matrix = compute_similarity_matrix(stocks)

plt.figure(figsize=(12, 10))
sns.heatmap(similarity_matrix, cmap='coolwarm', center=0)
plt.title("Stock Similarity Matrix")
plt.show()
```

## ğŸ§ª í…ŒìŠ¤íŠ¸

### ìœ ë‹› í…ŒìŠ¤íŠ¸

```python
def test_embedding_dimension():
    embedder = TimeSeriesEmbedding()
    prices = np.random.randn(252)

    embedding = embedder.create_embedding(prices)

    assert embedding.shape == (25,)
    assert np.linalg.norm(embedding) > 0

def test_similarity_symmetry():
    # sim(A, B) == sim(B, A)
    sim_ab = vector_db.compute_similarity(stock_a, stock_b)
    sim_ba = vector_db.compute_similarity(stock_b, stock_a)

    assert abs(sim_ab - sim_ba) < 1e-6
```

### í†µí•© í…ŒìŠ¤íŠ¸

```python
def test_end_to_end():
    # 1. ì¸ë±ì‹±
    vector_db.index_stock('005930', prices_samsung)
    vector_db.index_stock('000660', prices_sk)

    # 2. ê²€ìƒ‰
    similar = vector_db.search_similar_stocks('005930', top_k=5)

    # 3. ê²€ì¦
    assert '000660' in [code for code, _ in similar]
```

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Qdrant ì—°ê²° ì‹¤íŒ¨

```bash
# ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
docker ps | grep qdrant

# ë¡œê·¸ í™•ì¸
docker logs cybos-qdrant

# ì¬ì‹œì‘
docker-compose restart qdrant
```

### ì„ë² ë”© ì°¨ì› ë¶ˆì¼ì¹˜

```python
# ì»¬ë ‰ì…˜ ì¬ìƒì„±
vector_db.client.delete_collection("stock_timeseries")
vector_db.initialize_collection()
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±

```python
# ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
def batch_index_stocks_chunked(stock_codes, chunk_size=10):
    for i in range(0, len(stock_codes), chunk_size):
        chunk = stock_codes[i:i+chunk_size]
        batch_index_stocks(chunk)
```

## ğŸ“Š ë²¤ì¹˜ë§ˆí¬

### ê²€ìƒ‰ ì†ë„

```
- 100ê°œ ì¢…ëª©: < 10ms
- 1,000ê°œ ì¢…ëª©: < 50ms
- 10,000ê°œ ì¢…ëª©: < 200ms
```

### ì •í™•ë„

```
Recall@10 (ìƒìœ„ 10ê°œ ì •í™•ë„):
- HNSW (ef=128): 95%
- HNSW (ef=64): 90%
- Linear Search: 100% (ë§¤ìš° ëŠë¦¼)
```

## ğŸ”® í–¥í›„ ê³„íš

1. **ë”¥ëŸ¬ë‹ ì„ë² ë”©**
   - Transformer ê¸°ë°˜ ì‹œê³„ì—´ ì„ë² ë”©
   - ìê¸°ì§€ë„ í•™ìŠµ (Self-supervised)

2. **ë‹¤ì¤‘ ì‹œê°„ í•´ìƒë„**
   - 1ë¶„ë´‰, 5ë¶„ë´‰, ì¼ë´‰ í†µí•©

3. **ì˜¨ë¼ì¸ í•™ìŠµ**
   - ì‹¤ì‹œê°„ ì„ë² ë”© ì—…ë°ì´íŠ¸

## ğŸ“š ì°¸ê³  ìë£Œ

- [Qdrant Documentation](https://qdrant.tech/documentation/)
- [HNSW Algorithm](https://arxiv.org/abs/1603.09320)
- [Time Series Embedding](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf)

## ğŸ¤ ê¸°ì—¬

ìƒˆë¡œìš´ íŠ¹ì§• ì¶”ì¶œ ë°©ë²•ì´ë‚˜ ì„ë² ë”© ëª¨ë¸ì´ ìˆë‹¤ë©´ PR í™˜ì˜í•©ë‹ˆë‹¤!
