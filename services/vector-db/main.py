"""
Vector DB Service - ì‹œê³„ì—´ ì„ë² ë”© ë° ìœ ì‚¬ë„ ê²€ìƒ‰ ì„œë¹„ìŠ¤

ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ë²¡í„°ë¡œ ì„ë² ë”©í•˜ê³  Qdrantì— ì €ì¥í•˜ì—¬
ìœ ì‚¬í•œ ì£¼ì‹ íŒ¨í„´ì„ ë¹ ë¥´ê²Œ ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.
"""

import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

import numpy as np
import pandas as pd
from typing import List, Dict, Optional, Tuple
from datetime import datetime, timedelta

from qdrant_client import QdrantClient
from qdrant_client.models import (
    Distance,
    VectorParams,
    PointStruct,
    Filter,
    FieldCondition,
    MatchValue
)

from sklearn.preprocessing import StandardScaler
from scipy.stats import skew, kurtosis

from src.database.connection import get_connection_context
from src.database.models.history import HistoryTable, HistoryTimeframe


class TimeSeriesEmbedding:
    """ì‹œê³„ì—´ ë°ì´í„° ì„ë² ë”©"""

    @staticmethod
    def extract_statistical_features(prices: np.ndarray) -> np.ndarray:
        """
        í†µê³„ì  íŠ¹ì§• ì¶”ì¶œ
        - ìˆ˜ìµë¥  í‰ê· , í‘œì¤€í¸ì°¨
        - ì™œë„(Skewness), ì²¨ë„(Kurtosis)
        - ìµœëŒ€ ë‚™í­(Max Drawdown)
        - ìƒ¤í”„ ë¹„ìœ¨ ì¶”ì •
        """
        if len(prices) < 2:
            return np.zeros(10)

        # ìˆ˜ìµë¥  ê³„ì‚°
        returns = np.diff(np.log(prices))

        features = []

        # ê¸°ë³¸ í†µê³„
        features.append(np.mean(returns))           # í‰ê·  ìˆ˜ìµë¥ 
        features.append(np.std(returns))            # ë³€ë™ì„±
        features.append(skew(returns))              # ì™œë„
        features.append(kurtosis(returns))          # ì²¨ë„

        # ë¦¬ìŠ¤í¬ ë©”íŠ¸ë¦­
        sharpe = np.mean(returns) / (np.std(returns) + 1e-10)
        features.append(sharpe)                     # ìƒ¤í”„ ë¹„ìœ¨

        # ìµœëŒ€ ë‚™í­
        cumulative = np.cumprod(1 + returns)
        running_max = np.maximum.accumulate(cumulative)
        drawdown = (cumulative - running_max) / running_max
        max_dd = np.min(drawdown)
        features.append(max_dd)                     # ìµœëŒ€ ë‚™í­

        # ëª¨ë©˜í…€ ì§€í‘œ
        features.append(returns[-5:].mean())        # ìµœê·¼ 5ì¼ í‰ê· 
        features.append(returns[-20:].mean())       # ìµœê·¼ 20ì¼ í‰ê· 
        features.append(returns[-60:].mean())       # ìµœê·¼ 60ì¼ í‰ê· 

        # ë³€ë™ì„± ë¹„ìœ¨
        vol_ratio = np.std(returns[-20:]) / (np.std(returns) + 1e-10)
        features.append(vol_ratio)                  # ìµœê·¼ ë³€ë™ì„± ë¹„ìœ¨

        return np.array(features)

    @staticmethod
    def extract_shape_features(prices: np.ndarray, n_segments: int = 10) -> np.ndarray:
        """
        ì‹œê³„ì—´ í˜•íƒœ íŠ¹ì§• ì¶”ì¶œ (Piecewise Aggregate Approximation)
        """
        if len(prices) < n_segments:
            return np.zeros(n_segments)

        # ì •ê·œí™”
        normalized = (prices - np.mean(prices)) / (np.std(prices) + 1e-10)

        # êµ¬ê°„ë³„ í‰ê· 
        segment_size = len(normalized) // n_segments
        segments = []

        for i in range(n_segments):
            start = i * segment_size
            end = start + segment_size if i < n_segments - 1 else len(normalized)
            segments.append(np.mean(normalized[start:end]))

        return np.array(segments)

    @staticmethod
    def extract_frequency_features(prices: np.ndarray, n_coeff: int = 5) -> np.ndarray:
        """
        ì£¼íŒŒìˆ˜ ë„ë©”ì¸ íŠ¹ì§• ì¶”ì¶œ (FFT)
        """
        if len(prices) < n_coeff * 2:
            return np.zeros(n_coeff)

        # FFT ì ìš©
        fft = np.fft.fft(prices)
        fft_abs = np.abs(fft)

        # ìƒìœ„ Nê°œ ê³„ìˆ˜ë§Œ ì‚¬ìš©
        return fft_abs[1:n_coeff + 1]

    def create_embedding(self, prices: np.ndarray,
                        window_days: int = 60) -> np.ndarray:
        """
        ì¢…í•© ì„ë² ë”© ë²¡í„° ìƒì„±
        """
        if len(prices) < window_days:
            # ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë©´ 0 ë²¡í„° ë°˜í™˜
            return np.zeros(25)  # 10 + 10 + 5

        # ìµœê·¼ window_days ë°ì´í„°ë§Œ ì‚¬ìš©
        recent_prices = prices[-window_days:]

        # íŠ¹ì§• ì¶”ì¶œ
        stat_features = self.extract_statistical_features(recent_prices)        # 10
        shape_features = self.extract_shape_features(recent_prices, 10)         # 10
        freq_features = self.extract_frequency_features(recent_prices, 5)       # 5

        # ê²°í•©
        embedding = np.concatenate([stat_features, shape_features, freq_features])

        # ì •ê·œí™”
        embedding = embedding / (np.linalg.norm(embedding) + 1e-10)

        return embedding


class VectorDBService:
    """ë²¡í„° DB ì„œë¹„ìŠ¤ (Qdrant)"""

    def __init__(self, host: str = "localhost", port: int = 6333,
                 collection_name: str = "stock_timeseries"):
        self.client = QdrantClient(host=host, port=port)
        self.collection_name = collection_name
        self.embedding_dim = 25
        self.embedder = TimeSeriesEmbedding()

    def initialize_collection(self) -> None:
        """ì»¬ë ‰ì…˜ ì´ˆê¸°í™”"""
        try:
            # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ
            self.client.delete_collection(self.collection_name)
        except:
            pass

        # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
        self.client.create_collection(
            collection_name=self.collection_name,
            vectors_config=VectorParams(
                size=self.embedding_dim,
                distance=Distance.COSINE
            )
        )

        print(f"âœ… ì»¬ë ‰ì…˜ '{self.collection_name}' ìƒì„± ì™„ë£Œ")

    def index_stock(self, stock_code: str, prices: np.ndarray,
                   metadata: Optional[Dict] = None) -> None:
        """ì£¼ì‹ ì‹œê³„ì—´ ë°ì´í„° ì¸ë±ì‹±"""
        # ì„ë² ë”© ìƒì„±
        embedding = self.embedder.create_embedding(prices)

        # ë©”íƒ€ë°ì´í„°
        if metadata is None:
            metadata = {}

        metadata['stock_code'] = stock_code
        metadata['indexed_at'] = datetime.now().isoformat()

        # Qdrantì— ì €ì¥
        point = PointStruct(
            id=hash(stock_code) % (2**63),  # ê³ ìœ  ID ìƒì„±
            vector=embedding.tolist(),
            payload=metadata
        )

        self.client.upsert(
            collection_name=self.collection_name,
            points=[point]
        )

    def search_similar_stocks(self, stock_code: str,
                             top_k: int = 10) -> List[Tuple[str, float]]:
        """ìœ ì‚¬í•œ ì£¼ì‹ ê²€ìƒ‰"""
        # í•´ë‹¹ ì£¼ì‹ì˜ ë²¡í„° ê°€ì ¸ì˜¤ê¸°
        stock_id = hash(stock_code) % (2**63)

        try:
            stock_point = self.client.retrieve(
                collection_name=self.collection_name,
                ids=[stock_id]
            )

            if not stock_point:
                return []

            vector = stock_point[0].vector

            # ìœ ì‚¬ë„ ê²€ìƒ‰
            search_results = self.client.search(
                collection_name=self.collection_name,
                query_vector=vector,
                limit=top_k + 1  # ìê¸° ìì‹  ì œì™¸
            )

            # ê²°ê³¼ íŒŒì‹±
            similar_stocks = []
            for result in search_results:
                code = result.payload.get('stock_code')
                if code != stock_code:  # ìê¸° ìì‹  ì œì™¸
                    similar_stocks.append((code, result.score))

            return similar_stocks[:top_k]

        except Exception as e:
            print(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def batch_index_stocks(self, stock_codes: List[str],
                          db_path: str = "data/cybos.db",
                          window_days: int = 252) -> None:
        """ë°°ì¹˜ ì¸ë±ì‹±"""
        print(f"ğŸ”„ {len(stock_codes)}ê°œ ì¢…ëª© ì¸ë±ì‹± ì‹œì‘...")

        end_date = datetime.now().strftime("%Y-%m-%d")
        start_date = (datetime.now() - timedelta(days=window_days * 1.5)).strftime("%Y-%m-%d")

        success_count = 0

        with get_connection_context(db_path) as conn:
            for i, code in enumerate(stock_codes):
                if (i + 1) % 10 == 0:
                    print(f"  ì§„í–‰ë¥ : {i + 1}/{len(stock_codes)} ({(i + 1) / len(stock_codes) * 100:.1f}%)")

                try:
                    # íˆìŠ¤í† ë¦¬ ë°ì´í„° ì¡°íšŒ
                    history_list = HistoryTable.get_history(
                        conn, code, HistoryTimeframe.DAILY, start_date, end_date
                    )

                    if len(history_list) >= window_days:
                        prices = np.array([h.close_price for h in history_list])

                        # ë©”íƒ€ë°ì´í„°
                        metadata = {
                            'total_records': len(history_list),
                            'start_date': history_list[0].date,
                            'end_date': history_list[-1].date
                        }

                        # ì¸ë±ì‹±
                        self.index_stock(code, prices, metadata)
                        success_count += 1

                except Exception as e:
                    print(f"  âš ï¸  {code} ì¸ë±ì‹± ì‹¤íŒ¨: {e}")

        print(f"âœ… {success_count}ê°œ ì¢…ëª© ì¸ë±ì‹± ì™„ë£Œ")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ë²¡í„° DB ì„œë¹„ìŠ¤ ì‹œì‘")
    print("=" * 60)

    # ë²¡í„° DB ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    vector_db = VectorDBService()

    try:
        vector_db.initialize_collection()
    except Exception as e:
        print(f"âš ï¸  Qdrant ì—°ê²° ì‹¤íŒ¨: {e}")
        print("Dockerë¡œ Qdrantë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
        print("  docker run -p 6333:6333 qdrant/qdrant")
        return

    # KOSPI200 ì¢…ëª© ì¸ë±ì‹±
    from src.database.models.stock import StockTable

    with get_connection_context() as conn:
        kospi200_stocks = StockTable.get_kospi200_stocks(conn)
        stock_codes = [stock.code for stock in kospi200_stocks[:50]]  # í…ŒìŠ¤íŠ¸ìš© 50ê°œ

    # ë°°ì¹˜ ì¸ë±ì‹±
    vector_db.batch_index_stocks(stock_codes)

    # ìœ ì‚¬ ì¢…ëª© ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    if stock_codes:
        test_code = stock_codes[0]
        print(f"\nğŸ” '{test_code}' ì™€ ìœ ì‚¬í•œ ì¢…ëª© ê²€ìƒ‰:")

        similar = vector_db.search_similar_stocks(test_code, top_k=5)

        for i, (code, score) in enumerate(similar, 1):
            print(f"  {i}. {code} (ìœ ì‚¬ë„: {score:.4f})")


if __name__ == "__main__":
    main()
